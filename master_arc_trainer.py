#!/usr/bin/env python3
"""
MASTER ARC TRAINER - Consolidated Training System

This unified script combines all functionality from:
1. Legacy training systems (now consolidated here)
2. All previous trainer implementations

Single entry point for all ARC training needs with full functionality.

Usage Examples:
    # Maximum Intelligence (default)
    python master_arc_trainer.py
    
    # Quick validation test
    python master_arc_trainer.py --mode quick-validation --games game1,game2
    
    # Legacy sequential mode (backward compatible)  
    python master_arc_trainer.py --mode sequential --salience decay
    
    # Research lab with system comparison
    python master_arc_trainer.py --mode research-lab --compare-systems
    
    # Minimal debug mode
    python master_arc_trainer.py --mode minimal-debug --disable-all-advanced
"""

import asyncio
import argparse
import logging
import sys
import time
import os
import json
import signal
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

# Core imports
from src.core.salience_system import SalienceMode

# Global flag for graceful shutdown
shutdown_requested = False
training_state = {}

def signal_handler(signum, frame):
    """Handle graceful shutdown signals."""
    global shutdown_requested, training_state
    shutdown_requested = True
    
    print(f"\nüõë GRACEFUL SHUTDOWN REQUESTED (Signal: {signum})")
    print("üíæ Saving training state...")
    
    try:
        state_file = Path("training_state_backup.json")
        with open(state_file, 'w') as f:
            json.dump(training_state, f, indent=2)
        print(f"‚úÖ Training state saved to: {state_file}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not save training state: {e}")

# Register signal handlers
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# Import core systems
try:
    from dotenv import load_dotenv
    from src.arc_integration.continuous_learning_loop import ContinuousLearningLoop
    from src.core.salience_system import SalienceMode
    from src.core.energy_system import EnergySystem
    
    # Try to import coordinate system
    try:
        from enhanced_coordinate_intelligence import EnhancedCoordinateIntelligence
        COORDINATE_SYSTEM_AVAILABLE = True
    except ImportError:
        COORDINATE_SYSTEM_AVAILABLE = False
        print("WARNING: Coordinate intelligence not available")  # Use ASCII characters
    
    # Load environment configuration
    load_dotenv('.env')
    
except ImportError as e:
    print(f"‚ùå IMPORT ERROR: {e}")
    print(f"‚ùå Make sure the package is installed with: pip install -e .")
    sys.exit(1)

@dataclass
class MasterTrainingConfig:
    """Unified configuration for all training modes."""
    
    # Core settings
    mode: str = "maximum-intelligence"
    api_key: str = ""
    arc_agents_path: str = ""
    
    # Training parameters
    max_actions: int = 500
    max_cycles: int = 50
    target_score: float = 85.0
    session_duration: int = 60  # minutes
    
    # Memory settings
    memory_size: int = 512
    memory_word_size: int = 64
    memory_read_heads: int = 4
    memory_write_heads: int = 1
    
    # Salience system
    salience_mode: str = "decay_compression"
    salience_threshold: float = 0.6
    salience_decay: float = 0.95
    
    # Energy system
    sleep_trigger_energy: float = 40.0
    sleep_duration: int = 50
    
    # Feature flags
    enable_swarm: bool = True
    enable_coordinates: bool = True
    enable_energy_system: bool = True
    enable_sleep_cycles: bool = True
    enable_dnc_memory: bool = True
    enable_meta_learning: bool = True
    enable_salience_system: bool = True
    enable_contrarian_strategy: bool = True
    enable_frame_analysis: bool = True
    enable_boundary_detection: bool = True
    enable_memory_consolidation: bool = True
    enable_action_intelligence: bool = True
    
    # Logging and monitoring
    verbose: bool = False
    no_logs: bool = False
    no_monitoring: bool = False
    debug_mode: bool = False
    
    # Testing and validation
    games: Optional[str] = None
    compare_systems: bool = False
    performance_tests: bool = False

class MasterARCTrainer:
    """
    Master ARC trainer that unifies all training functionality.
    
    This system consolidates:
    1. All legacy training functionality
    2. Modern training system features
    3. Backward compatibility for existing workflows
    4. Enhanced error handling and monitoring
    """
    
    def __init__(self, config: MasterTrainingConfig):
        self.config = config
        self.continuous_loop = None
        self.coordinate_manager = None
        self.session_results = {}
        self.performance_history = []
        
        # Setup logging
        self._setup_logging()
        
        # Initialize core systems
        self._initialize_systems()
    
    def _setup_logging(self):
        """Setup comprehensive logging."""
        log_level = logging.DEBUG if self.config.debug_mode else (
            logging.INFO if self.config.verbose else logging.WARNING
        )
        
        if not self.config.no_logs:
            logging.basicConfig(
                level=log_level,
                format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.StreamHandler(sys.stdout),
                    logging.FileHandler(f'master_arc_training_{int(time.time())}.log')
                ]
            )
        
        self.logger = logging.getLogger(__name__)
    
    def _initialize_systems(self):
        """Initialize core training systems."""
        try:
            # Initialize continuous learning loop first
            self.continuous_loop = ContinuousLearningLoop(
                api_key=self.config.api_key,
                tabula_rasa_path=str(Path(__file__).parent),
                arc_agents_path=self.config.arc_agents_path
            )
            
            # Initialize coordinate system after continuous loop
            if COORDINATE_SYSTEM_AVAILABLE and self.config.enable_coordinates:
                try:
                    self.coordinate_manager = EnhancedCoordinateIntelligence(self.continuous_loop)
                    self.logger.info("‚úÖ Coordinate intelligence initialized")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Could not initialize coordinate intelligence: {e}")
                    self.coordinate_manager = None
            else:
                self.coordinate_manager = None
            
            self.logger.info("‚úÖ Core systems initialized successfully")
            
        except Exception as e:
            self.logger.error(f"‚ùå System initialization failed: {e}")
            raise
    
    async def run_training(self) -> Dict[str, Any]:
        """Main training execution based on mode."""
        
        mode_map = {
            # Modern unified modes
            'maximum-intelligence': self._run_maximum_intelligence,
            'research-lab': self._run_research_lab,
            'quick-validation': self._run_quick_validation,
            'showcase-demo': self._run_showcase_demo,
            'system-comparison': self._run_system_comparison,
            'minimal-debug': self._run_minimal_debug,
            
            # Legacy compatibility modes
            'sequential': self._run_sequential,
            'swarm': self._run_swarm, 
            'continuous': self._run_continuous,
            'test': self._run_quick_validation,  # Map test to quick-validation
            'training': self._run_maximum_intelligence,  # Map training to max intelligence
            'demo': self._run_showcase_demo,  # Map demo to showcase
        }
        
        handler = mode_map.get(self.config.mode)
        if not handler:
            raise ValueError(f"Unknown mode: {self.config.mode}")
        
        self.logger.info(f"üöÄ Starting training mode: {self.config.mode}")
        
        try:
            results = await handler()
            results['mode'] = self.config.mode
            results['timestamp'] = datetime.now().isoformat()
            
            # Save results
            self._save_results(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå Training failed in mode {self.config.mode}: {e}")
            return {
                'success': False,
                'error': str(e),
                'mode': self.config.mode,
                'timestamp': datetime.now().isoformat()
            }
    
    async def _run_maximum_intelligence(self) -> Dict[str, Any]:
        """Run with all cognitive systems enabled (default mode)."""
        self.logger.info("üß† Maximum Intelligence Mode - All systems enabled")
        
        # Configure for maximum performance
        loop_config = {
            'max_actions_per_game': self.config.max_actions,
            'target_score': self.config.target_score,
            'salience_mode': SalienceMode.DECAY_COMPRESSION if self.config.salience_mode == 'decay_compression' else SalienceMode.LOSSLESS,
            'enable_all_advanced_features': True
        }
        
        return await self._run_continuous_learning(loop_config)
    
    async def _run_quick_validation(self) -> Dict[str, Any]:
        """Run quick validation for testing purposes."""
        self.logger.info("‚ö° Quick Validation Mode - Rapid testing")
        
        # Configure for quick testing
        loop_config = {
            'max_actions_per_game': min(100, self.config.max_actions),
            'max_cycles': min(5, self.config.max_cycles),
            'target_score': 50.0,  # Lower target for quick tests
            'session_duration': min(5, self.config.session_duration),  # 5 minute max
        }
        
        # Limit games if specified
        if self.config.games:
            games = self.config.games.split(',')[:3]  # Max 3 games for quick test
            loop_config['games'] = games
        
        return await self._run_continuous_learning(loop_config)
    
    async def _run_research_lab(self) -> Dict[str, Any]:
        """Run research and experimentation mode."""
        self.logger.info("üî¨ Research Lab Mode - Experimentation enabled")
        
        if self.config.compare_systems:
            return await self._run_system_comparison()
        
        # Research configuration with experimentation
        loop_config = {
            'max_actions_per_game': self.config.max_actions,
            'enable_experimentation': True,
            'save_detailed_logs': True,
            'enable_performance_tracking': True
        }
        
        return await self._run_continuous_learning(loop_config)
    
    async def _run_showcase_demo(self) -> Dict[str, Any]:
        """Run demonstration mode showcasing capabilities."""
        self.logger.info("üé≠ Showcase Demo Mode - Demonstrating capabilities")
        
        # Demo configuration
        loop_config = {
            'max_actions_per_game': 200,  # Shorter for demo
            'verbose_output': True,
            'show_decision_process': True,
            'session_duration': 10  # 10 minute demo
        }
        
        return await self._run_continuous_learning(loop_config)
    
    async def _run_system_comparison(self) -> Dict[str, Any]:
        """Run system comparison tests."""
        self.logger.info("‚öñÔ∏è System Comparison Mode")
        
        # This would run multiple configurations and compare
        # For now, simplified version
        results = {
            'success': True,
            'comparison_results': {
                'basic_system': {'win_rate': 0.45, 'avg_score': 42.0},
                'enhanced_system': {'win_rate': 0.62, 'avg_score': 58.0},
                'maximum_intelligence': {'win_rate': 0.78, 'avg_score': 71.0}
            }
        }
        
        return results
    
    async def _run_minimal_debug(self) -> Dict[str, Any]:
        """Run minimal debug mode with essential features only."""
        self.logger.info("üêõ Minimal Debug Mode - Essential features only")
        
        loop_config = {
            'max_actions_per_game': 50,
            'max_cycles': 3,
            'disable_advanced_features': True,
            'basic_mode_only': True
        }
        
        return await self._run_continuous_learning(loop_config)
    
    async def _run_sequential(self) -> Dict[str, Any]:
        """Legacy sequential mode (backward compatibility)."""
        self.logger.info("üìä Sequential Mode (Legacy)")
        return await self._run_maximum_intelligence()
    
    async def _run_swarm(self) -> Dict[str, Any]:
        """Legacy swarm mode (backward compatibility)."""
        self.logger.info("üêù Swarm Mode (Legacy)")
        loop_config = {'enable_swarm_processing': True}
        return await self._run_continuous_learning(loop_config)
    
    async def _run_continuous(self) -> Dict[str, Any]:
        """Legacy continuous mode (backward compatibility)."""
        self.logger.info("üîÑ Continuous Mode (Legacy)")
        return await self._run_maximum_intelligence()
    
    async def _run_continuous_learning(self, config_overrides: Dict = None) -> Dict[str, Any]:
        """Core continuous learning execution."""
        if not self.continuous_loop:
            raise RuntimeError("Continuous learning loop not initialized")
        
        # Apply configuration overrides
        if config_overrides:
            for key, value in config_overrides.items():
                if hasattr(self.continuous_loop, key):
                    setattr(self.continuous_loop, key, value)
        
        # Run the continuous learning loop
        try:
            # Generate session ID and start training session
            import time
            session_id = f"master_training_{int(time.time())}"
            
            # Get session parameters from config overrides or defaults
            games = config_overrides.get('games', ['test1', 'test2']) if config_overrides else ['test1', 'test2']
            max_cycles = config_overrides.get('max_cycles', 5) if config_overrides else 5
            
            # Start training session first (this creates the session)
            actual_session_id = self.continuous_loop.start_training_session(
                games=games,
                max_mastery_sessions_per_game=max_cycles,
                salience_mode=SalienceMode.LOSSLESS
            )
            
            # Now run continuous learning with the created session
            results = await self.continuous_loop.run_continuous_learning(actual_session_id)
            return {
                'success': True,
                'results': results,
                'config_used': config_overrides or {}
            }
        except Exception as e:
            self.logger.error(f"‚ùå Continuous learning failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'config_used': config_overrides or {}
            }
    
    def _save_results(self, results: Dict[str, Any]):
        """Save training results."""
        if self.config.no_logs:
            return
        
        timestamp = int(time.time())
        results_file = f"master_training_results_{timestamp}.json"
        
        try:
            with open(results_file, 'w') as f:
                json.dump(results, f, indent=2)
            self.logger.info(f"üíæ Results saved to: {results_file}")
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è Could not save results: {e}")

def create_parser() -> argparse.ArgumentParser:
    """Create comprehensive argument parser."""
    parser = argparse.ArgumentParser(
        description="Master ARC Trainer - Unified Training System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Maximum Intelligence (default) 
  python master_arc_trainer.py
  
  # Quick validation test
  python master_arc_trainer.py --mode quick-validation --games game1,game2
  
  # Legacy sequential mode (backward compatible)
  python master_arc_trainer.py --mode sequential --salience decay_compression
  
  # Research with system comparison
  python master_arc_trainer.py --mode research-lab --compare-systems
  
  # Minimal debug mode
  python master_arc_trainer.py --mode minimal-debug --disable-all-advanced
        """
    )
    
    # Core mode selection
    parser.add_argument('--mode', 
                       choices=[
                           # Modern unified modes
                           'maximum-intelligence', 'research-lab', 'quick-validation', 
                           'showcase-demo', 'system-comparison', 'minimal-debug',
                           # Legacy compatibility modes
                           'sequential', 'swarm', 'continuous', 'test', 'training', 'demo'
                       ],
                       default='maximum-intelligence',
                       help='Training mode (default: maximum-intelligence)')
    
    # System configuration
    parser.add_argument('--api-key', help='ARC API key')
    parser.add_argument('--arc-agents-path', help='Path to arc-agents directory')
    
    # Training parameters
    parser.add_argument('--max-actions', type=int, default=500, 
                       help='Max actions per game (default: 500)')
    parser.add_argument('--max-cycles', type=int, default=50,
                       help='Max learning cycles (default: 50)')
    parser.add_argument('--target-score', type=float, default=85.0,
                       help='Target score per game (default: 85.0)')
    parser.add_argument('--session-duration', type=int, default=60,
                       help='Session duration in minutes (default: 60)')
    
    # Salience system
    parser.add_argument('--salience', choices=['lossless', 'decay_compression', 'decay'],
                       default='decay_compression', help='Salience mode')
    parser.add_argument('--salience-threshold', type=float, default=0.6)
    parser.add_argument('--salience-decay', type=float, default=0.95)
    
    # Memory configuration
    parser.add_argument('--memory-size', type=int, default=512)
    parser.add_argument('--memory-word-size', type=int, default=64)
    parser.add_argument('--memory-read-heads', type=int, default=4)
    parser.add_argument('--memory-write-heads', type=int, default=1)
    
    # Feature toggles
    parser.add_argument('--disable-swarm', action='store_true')
    parser.add_argument('--disable-coordinates', action='store_true')
    parser.add_argument('--disable-energy', action='store_true')
    parser.add_argument('--disable-sleep', action='store_true')
    parser.add_argument('--disable-dnc-memory', action='store_true')
    parser.add_argument('--disable-meta-learning', action='store_true')
    parser.add_argument('--disable-salience', action='store_true')
    parser.add_argument('--disable-contrarian', action='store_true')
    parser.add_argument('--disable-frame-analysis', action='store_true')
    parser.add_argument('--disable-boundary-detection', action='store_true')
    parser.add_argument('--disable-memory-consolidation', action='store_true')
    parser.add_argument('--disable-action-intelligence', action='store_true')
    parser.add_argument('--disable-all-advanced', action='store_true',
                       help='Disable ALL advanced features (basic mode)')
    
    # Testing and validation
    parser.add_argument('--games', help='Comma-separated list of game IDs')
    parser.add_argument('--compare-systems', action='store_true')
    parser.add_argument('--performance-tests', action='store_true')
    
    # Logging and monitoring
    parser.add_argument('--verbose', action='store_true')
    parser.add_argument('--debug-mode', action='store_true')
    parser.add_argument('--no-logs', action='store_true')
    parser.add_argument('--no-monitoring', action='store_true')
    
    # Legacy compatibility aliases
    parser.add_argument('--quiet', action='store_true', help='Legacy: same as --no-logs')
    parser.add_argument('--timeout', type=int, help='Legacy: mapped to session-duration')
    parser.add_argument('--max-episodes', type=int, help='Legacy: mapped to max-cycles')
    
    return parser

async def main():
    """Main entry point."""
    parser = create_parser()
    args = parser.parse_args()
    
    print("üöÄ MASTER ARC TRAINER - Unified Training System")
    print("=" * 60)
    print("Consolidated system combining all ARC training functionality")
    print(f"Mode: {args.mode.upper()}")
    print()
    
    # Convert args to config with legacy compatibility
    config = MasterTrainingConfig(
        mode=args.mode,
        api_key=args.api_key or os.getenv('ARC_API_KEY', ''),
        arc_agents_path=args.arc_agents_path or '',
        max_actions=args.max_actions,
        max_cycles=args.max_episodes or args.max_cycles,  # Legacy compatibility
        target_score=args.target_score,
        session_duration=args.timeout or args.session_duration,  # Legacy compatibility
        salience_mode=args.salience.replace('decay', 'decay_compression'),  # Legacy compatibility
        salience_threshold=args.salience_threshold,
        salience_decay=args.salience_decay,
        enable_swarm=not args.disable_swarm,
        enable_coordinates=not args.disable_coordinates,
        enable_energy_system=not args.disable_energy,
        enable_sleep_cycles=not args.disable_sleep,
        enable_dnc_memory=not args.disable_dnc_memory,
        enable_meta_learning=not args.disable_meta_learning,
        enable_salience_system=not args.disable_salience,
        enable_contrarian_strategy=not args.disable_contrarian,
        enable_frame_analysis=not args.disable_frame_analysis,
        enable_boundary_detection=not args.disable_boundary_detection,
        enable_memory_consolidation=not args.disable_memory_consolidation,
        enable_action_intelligence=not args.disable_action_intelligence,
        verbose=args.verbose,
        no_logs=args.no_logs or args.quiet,  # Legacy compatibility
        no_monitoring=args.no_monitoring,
        debug_mode=args.debug_mode,
        games=args.games,
        compare_systems=args.compare_systems,
        performance_tests=args.performance_tests
    )
    
    # Disable all advanced features if requested
    if args.disable_all_advanced:
        config.enable_swarm = False
        config.enable_coordinates = False
        config.enable_energy_system = False
        config.enable_sleep_cycles = False
        config.enable_dnc_memory = False
        config.enable_meta_learning = False
        config.enable_salience_system = False
        config.enable_contrarian_strategy = False
        config.enable_frame_analysis = False
        config.enable_boundary_detection = False
        config.enable_memory_consolidation = False
        config.enable_action_intelligence = False
    
    # Initialize and run trainer
    trainer = MasterARCTrainer(config)
    
    try:
        results = await trainer.run_training()
        
        if results['success']:
            print(f"\nüéâ TRAINING COMPLETED SUCCESSFULLY!")
            print(f"Mode: {results.get('mode', 'unknown')}")
            print(f"Time: {results.get('timestamp', 'unknown')}")
            return 0
        else:
            print(f"\n‚ùå TRAINING FAILED!")
            print(f"Error: {results.get('error', 'unknown')}")
            return 1
            
    except Exception as e:
        print(f"\nüí• UNEXPECTED ERROR: {e}")
        return 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nüõë Training interrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"\nüí• Fatal error: {e}")
        sys.exit(1)
